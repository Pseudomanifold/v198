---
abstract: Using graph neural networks for large graphs is challenging since there
  is no clear way of constructing mini-batches. To solve this, previous methods have
  relied on sampling or graph clustering. While these approaches often lead to good
  training convergence, they introduce significant overhead due to expensive random
  data accesses and perform poorly during inference. In this work we instead focus
  on model behavior during inference. We theoretically model batch construction via
  maximizing the influence score of nodes on the outputs. This formulation leads to
  optimal approximation of the output when we do not have knowledge of the trained
  model. We call the resulting method influence-based mini-batching (IBMB). IBMB accelerates
  inference by up to 130x compared to previous methods that reach similar accuracy.
  Remarkably, with adaptive optimization and the right training schedule IBMB can
  also substantially accelerate training, thanks to precomputed batches and consecutive
  memory accesses. This results in up to 18x faster training per epoch and up to 17x
  faster convergence per runtime compared to previous methods.
openreview: b9g0vxzYa_
section: Oral Presentations
software: https://github.com/tum-daml/ibmb
title: Influence-Based Mini-Batching for Graph Neural Networks
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gasteiger22a
month: 0
tex_title: Influence-Based Mini-Batching for Graph Neural Networks
firstpage: '9:1'
lastpage: '9:19'
page: 9:1-9:19
order: 9
cycles: false
bibtex_author: Gasteiger, Johannes and Qian, Chendi and G{\"u}nnemann, Stephan
author:
- given: Johannes
  family: Gasteiger
- given: Chendi
  family: Qian
- given: Stephan
  family: GÃ¼nnemann
date: 2022-12-21
address:
container-title: Proceedings of the First Learning on Graphs Conference
volume: '198'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 12
  - 21
pdf: https://proceedings.mlr.press/v198/gasteiger22a/gasteiger22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
