---
abstract: Recent works have impressively demonstrated that there exists a subnetwork
  in randomly initialized convolutional neural networks (CNNs) that can match the
  performance of the fully trained dense networks at initialization, without any optimization
  of the weights of the network (i.e., untrained networks). However, the presence
  of such untrained subnetworks in graph neural networks (GNNs) still remains mysterious.
  In this paper we carry out the first-of-its-kind exploration of discovering matching
  untrained GNNs. With sparsity as the core tool, we can find untrained sparse subnetworks
  at the initialization, that can match the performance of fully trained dense GNNs.
  Besides this already encouraging finding of comparable performance, we show that
  the found untrained subnetworks can substantially mitigate the GNN over-smoothing
  problem, hence becoming a powerful tool to enable deeper GNNs without bells and
  whistles. We also observe that such sparse untrained subnetworks have appealing
  performance in out-of-distribution detection and robustness of input perturbations.
  We evaluate our method across widely-used GNN architectures on various popular datasets
  including the Open Graph Benchmark (OGB).
openreview: dF6aEW3_62O
section: Oral Presentations
software: https://github.com/TienjinHuang/UGTs-LoG.git
title: 'You Can Have Better Graph Neural Networks by Not Training Weights at All:
  Finding Untrained GNNs Tickets'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: huang22a
month: 0
tex_title: 'You Can Have Better Graph Neural Networks by Not Training Weights at All:
  Finding Untrained GNNs Tickets'
firstpage: '8:1'
lastpage: '8:17'
page: 8:1-8:17
order: 8
cycles: false
bibtex_author: Huang, Tianjin and Chen, Tianlong and Fang, Meng and Menkovski, Vlado
  and Zhao, Jiaxu and Yin, Lu and Pei, Yulong and Mocanu, Decebal Constantin and Wang,
  Zhangyang and Pechenizkiy, Mykola and Liu, Shiwei
author:
- given: Tianjin
  family: Huang
- given: Tianlong
  family: Chen
- given: Meng
  family: Fang
- given: Vlado
  family: Menkovski
- given: Jiaxu
  family: Zhao
- given: Lu
  family: Yin
- given: Yulong
  family: Pei
- given: Decebal Constantin
  family: Mocanu
- given: Zhangyang
  family: Wang
- given: Mykola
  family: Pechenizkiy
- given: Shiwei
  family: Liu
date: 2022-12-21
address:
container-title: Proceedings of the First Learning on Graphs Conference
volume: '198'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 12
  - 21
pdf: https://proceedings.mlr.press/v198/huang22a/huang22a.pdf
extras:
- label: Supplementary ZIP
  link: https://proceedings.mlr.press/v198/huang22a/huang22a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
